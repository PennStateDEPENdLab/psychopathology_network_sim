---
title: "Initial simulations of SEM - network similarity"
author: "Michael Hallquist"
date: "2/20/2017"
output:
  html_document:
    toc: true
    theme: flatly
  html_notebook: default
  pdf_document: default
---

```{r setup, include=FALSE}
options(width = 100)
rd <- file.path(getMainDir(), "psychopathology_network_sim")
if (!require(pacman)) { install.packages("pacman"); library(pacman) }
p_load(knitr, dplyr, ggplot2, tidyr, cowplot, simsem, bootnet, 
       qgraph, abind, foreach, doParallel)
library()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rd)
source(file.path(rd, "code/psychopathology_sim_functions.R"))
```

This document summarizes initial simulation results describing how network analysis measures
of centrality describe latent trait structures generated by traditional (confirmatory) factor models.
The overarching idea is that network metrics will describe aspects of the latent
structure that are largely redundant with parameters available in conventional
CFA.

The basic simulation structure uses standardidized factors (variance = 1.0) and equates item residual variances. Data are simulated using the `simsem` package in `R` based on `lavaan` syntax that generates the model-implied mean and covariance structure.

## Conceptual background
  ### Formal model versus secondary descriptive statistics
    Analysis of factor loadings or residual correlation distributions in CFA in equivalent of centrality measures of graphs
  ### Ontological problems

## Specific hypotheses

* H1: In factor models with simple structure, strength centrality (or degree for
  binarized networks) will be redundant with factor loadings.
    + Corollary: The relationship between strength centrality and factor
    loadings will not diminish as the number of factors increases because
    strength is concerned with the summed connection magnitude and is not
    based on distance between nodes (building on path).
* H2: In one-factor models with conditional independence among items, both strength centrality
  and closeness centrality will be redundant with factor loadings. Closeness measures the average length of the shortest path between a target node and all other nodes in the graph
* H3: In *n*-factor structures with simple structure, decomposing the graph into subgraphs (either through community detection algorithms or by extracting connected components), then all of the 1-factor results will hold (metrics within factors).
* H4: In a 2-factor structure, betweenness will correlate moderately with the magnitude of a cross-loading (unpack)
* H5: In a 2-factor structure, the magnitude of a bivariate residual correlation will strongly correlate with the betweenness of the two variables.


## TESTS:
1. Scale up cross loading in a 2-factor structure that otherwise remains static
2. Look at strength and degree in 2-, 3-, and 4-factor models. For degree, perhaps threshold at 0.4 density -- or even use a range?
3. For the decomposition analysis, use modularity analysis or largest connected component decomposition, then compute metrics within subgraphs

## H1 simulations: redundancy of factor loadings with strength (and degree) centrality

### Basic one-factor simulation
Simulate data from a one-factor CFA with 10 indicators, 200 replications,
*N*=400, and factor loadings drawn from a random uniform sampler between .4 and
.95. Assume equal residual variance of 0.3 (30% unexplained variance). Twenty
"examples" are generated: an example in my shorthand is a replication of the
meta-structure to ensure that results are not peculiar to a given set of replications
or loadings.

```{r sim_1fac, cache=TRUE, include=FALSE}
if (file.exists("data/onefac_cfa_20examples_200reps_n400.RData")) {
  load("data/onefac_cfa_20examples_200reps_n400.RData")
} else {
dd <- demomaster(nexamples=20, nindicators=10, nfactors=1, nreplications=200, n=400, 
    loadingsampler=seq(.4, .95, .05), errorvars="eqresidvar", ivar=0.3, thetacorlist=NULL)
save(file="data/onefac_cfa_20examples_200reps_n400.RData", dd)
}
```

Means and standard deviations of the association of factor loadings with graph centrality measures
for one-factor setup
```{r analyze_1fac, dependson="sim_1fac"}

##just get a mean and SD of correlations between each nodal measure and factor loadings
corrvgraph_glasso <- do.call(rbind, lapply(dd, function(example) { example$graph_v_factor$EBICglasso$corr_v_fitted }))
corrvgraph_pcor <- do.call(rbind, lapply(dd, function(example) { example$graph_v_factor$pcor$corr_v_fitted }))

kable(corrvgraph_glasso %>% group_by(measure, factor) %>% summarize_all(funs(mean, sd)), 
      digits=2, caption = "Association of GLASSO graph measures with 1-factor CFA loadings")
kable(corrvgraph_pcor %>% group_by(measure, factor) %>% summarize_all(funs(mean, sd)), 
      digits=2, caption = "Association of PCOR graph measures with 1-factor CFA loadings")
```

### Two-factor simulation
20 indicators (10 per factor) with random loadings and equal residual variances as above
```{r sim_2fac, cache=TRUE, include=FALSE}
if (file.exists("data/twofac_cfa_20examples_200reps_n400.RData")) {
  load("data/twofac_cfa_20examples_200reps_n400.RData")
} else {
dd2 <- demomaster(nexamples=20, nindicators=20, nfactors=2, nreplications=200, n=400, 
    loadingsampler=seq(.4, .95, .05), errorvars="eqresidvar", ivar=0.3, thetacorlist=NULL)
save(file="data/twofac_cfa_20examples_200reps_n400.RData", dd2)
}
```

Note that GLASSO maintains a high corrleation
```{r analyze_2fac, dependson="sim_2fac"}
corrvgraph_glasso <- do.call(rbind, lapply(dd2, function(example) { example$graph_v_factor$EBICglasso$corr_v_fitted }))
corrvgraph_pcor <- do.call(rbind, lapply(dd2, function(example) { example$graph_v_factor$pcor$corr_v_fitted }))

kable(corrvgraph_glasso %>% group_by(measure, factor) %>% summarize_all(funs(mean, sd)), 
      digits=2, caption = "Association of GLASSO graph measures with 2-factor CFA loadings")
kable(corrvgraph_pcor %>% group_by(measure, factor) %>% summarize_all(funs(mean, sd)),
      digits=2, caption = "Association of PCOR graph measures with 2-factor CFA loadings")
```

### Hypothesis 4
In a 2-factor (or larger) structure, betweenness will be associated with the magnitude of an
item cross-loading. Here, we lock in a specific 2-factor structure and vary the magnitude of a single cross
loading. The factor structure is 0.6 loadings of y1-y9 on f1, and 0.6 of y10-y18 on f2.
We then add a cross-loading of y2 on f2 that varies randomly in magnitude from 0.2 - 0.8

```{r sim_2fac_cross, cache=TRUE, include=FALSE}
##need to lock in a given factor structure, then vary the cross-loading magnitude.

#consistent 2-factor structure
lambda <- as.matrix(rbind(
        c(rep(0.6, 9), rep(0, 9)), #f1
        c(rep(0, 9), rep(0.6, 9)))) #f2

varnames <- paste0("y", 1:ncol(lambda))

fvar <- c(1.0, 1.0) #factor variance (standardized)
errorvars <- rep(0.3, ncol(lambda)) #fixed error specification
#errorvars <- computeResidvar(targetitemvar=1.0, lambda, fvar=fvar) #compute item residual variances assuming equal observed variances 
theta <- diag(as.vector(errorvars)) #0 resid cov initially
rownames(theta) <- colnames(theta) <- varnames #necessary for addErrorCor to work

psi <- diag(fvar) #zero covariance in factor structure at the moment
dimnames(psi) <- list(f=paste0("f", 1:nrow(psi)), f=paste0("f", 1:ncol(psi)))

#model specification structure. Currently just wrapping up individual arguments above into a list
model1 <- list(
    varnames=varnames, #vector of variable names
    lambda=lambda, #nitems x nfactors loadings matrix
    theta=theta, #covariance (residual) matrix for observed items
    psi=psi #covariance matrix for factors
)

#add one cross-loading in 200 replications
cl <- makeCluster(8) #defaults to PSOCK cluster
clusterExport(cl, c("simCFAGraphs"))

registerDoParallel(cl)
clusterEvalQ(cl, library(dplyr)) #load dplyr in all workers
mlist <- foreach(i=1:200) %dopar% {
      mm <- model1
      mm$lambda[2, 2] <- runif(1, 0.2, 0.8) #add cross-loading of y2 onto f2
      sims <- simCFAGraphs(mm, nreplications=1, n=400, thetastart=TRUE, parallel=0)
      return(sims)
}
stopCluster(cl)
```

```{r, dependson="sim_2fac_cross", include=FALSE}
#wrangling of output structure
#will return a data.frame with betweenness for y2 (cross-loaded item) and the population
#and fitted loadings for both factors
bmat <- do.call(rbind, lapply(mlist, function(rep) {
  brep <- filter(rep$graph_v_factor$EBICglasso$metric_v_loadings, node=="y2" & measure=="betweenness")
}))

bmat$graphNum <- rep(1:(nrow(bmat)/2), each=2) #bmat has two rows per replication. Need to identify these to get the spread to work properly

smat <- do.call(rbind, lapply(mlist, function(rep) {
  brep <- filter(rep$graph_v_factor$EBICglasso$metric_v_loadings, node=="y2" & measure=="strength")
}))

smat$graphNum <- rep(1:(nrow(smat)/2), each=2) #smat has two rows per replication. Need to identify these to get the spread to work properly

cmat <- do.call(rbind, lapply(mlist, function(rep) {
  brep <- filter(rep$graph_v_factor$EBICglasso$metric_v_loadings, node=="y2" & measure=="closeness")
}))

cmat$graphNum <- rep(1:(nrow(cmat)/2), each=2) #smat has two rows per replication. Need to identify these to get the spread to work properly
```

Conclusion: we do not see support for an association of the cross-loading with
node betweenness.

Correlation of fitted loading with primary factor (loading varies ~0.6)
```{r dependson="sim_2fac_cross"}
#correlation of node betweenness and core factor
cor.test(~ fittedloading + value, filter(bmat, factor=="f1"))

bb <- bmat %>% select(graphNum, value, factor, fittedloading) %>% spread(key=factor, value=fittedloading) #graphNum contains the identifying column
ggplot(bb, aes(x=f1, y=value)) + geom_point() + stat_smooth()
```

Correlation of fitted loading with secondary factor (runif 0.2--0.8)
```{r dependson="sim_2fac_cross"}
#correlation of node betweenness and core factor
cor.test(~ fittedloading + value, filter(bmat, factor=="f2"))
ggplot(bb, aes(x=f2, y=value)) + geom_point() + stat_smooth()
```

Join prediction of betweenness by both loadings
```{r dependson="sim_2fac_cross"}
summary(lm(value ~ f1 + f2, bb))
```

Notably, however, this idea is strongly supported for both closeness and strength centrality

*Closeness*

Correlation of fitted loading with primary factor (loading varies ~0.6)
```{r dependson="sim_2fac_cross"}
#correlation of node betweenness and core factor
cor.test(~ fittedloading + value, filter(cmat, factor=="f1"))

bb <- cmat %>% select(graphNum, value, factor, fittedloading) %>% spread(key=factor, value=fittedloading) #graphNum contains the identifying column
ggplot(bb, aes(x=f1, y=value)) + geom_point() + stat_smooth()
```

Correlation of fitted loading with secondary factor (runif 0.2--0.8)
```{r dependson="sim_2fac_cross"}
#correlation of node betweenness and core factor
cor.test(~ fittedloading + value, filter(cmat, factor=="f2"))
ggplot(bb, aes(x=f2, y=value)) + geom_point() + stat_smooth()
```

Join prediction of betweenness by both loadings
```{r dependson="sim_2fac_cross"}
summary(lm(value ~ f1 + f2, bb))
```

*Strength*
Correlation of fitted loading with primary factor (loading varies ~0.6)
```{r dependson="sim_2fac_cross"}
#correlation of node betweenness and core factor
cor.test(~ fittedloading + value, filter(smat, factor=="f1"))

bb <- smat %>% select(graphNum, value, factor, fittedloading) %>% spread(key=factor, value=fittedloading) #graphNum contains the identifying column
ggplot(bb, aes(x=f1, y=value)) + geom_point() + stat_smooth()
```

Correlation of fitted loading with secondary factor (runif 0.2--0.8)
```{r dependson="sim_2fac_cross"}
#correlation of node betweenness and core factor
cor.test(~ fittedloading + value, filter(smat, factor=="f2"))
ggplot(bb, aes(x=f2, y=value)) + geom_point() + stat_smooth()
```

Join prediction of betweenness by both loadings
```{r dependson="sim_2fac_cross"}
summary(lm(value ~ f1 + f2, bb))
```


### What if we allow the loading on each factor to vary?

```{r sim_2fac_cross_rand, cache=TRUE, include=FALSE}
##need to lock in a given factor structure, then vary the cross-loading magnitude.

#consistent 2-factor structure
lambda <- as.matrix(rbind(
        c(rep(0.6, 9), rep(0, 9)), #f1
        c(rep(0, 9), rep(0.6, 9)))) #f2

varnames <- paste0("y", 1:ncol(lambda))

fvar <- c(1.0, 1.0) #factor variance (standardized)
errorvars <- rep(0.3, ncol(lambda)) #fixed error specification
#errorvars <- computeResidvar(targetitemvar=1.0, lambda, fvar=fvar) #compute item residual variances assuming equal observed variances 
theta <- diag(as.vector(errorvars)) #0 resid cov initially
rownames(theta) <- colnames(theta) <- varnames #necessary for addErrorCor to work

psi <- diag(fvar) #zero covariance in factor structure at the moment
dimnames(psi) <- list(f=paste0("f", 1:nrow(psi)), f=paste0("f", 1:ncol(psi)))

#model specification structure. Currently just wrapping up individual arguments above into a list
model1 <- list(
    varnames=varnames, #vector of variable names
    lambda=lambda, #nitems x nfactors loadings matrix
    theta=theta, #covariance (residual) matrix for observed items
    psi=psi #covariance matrix for factors
)

cl <- makeCluster(8) #defaults to PSOCK cluster
clusterExport(cl, c("simCFAGraphs"))

registerDoParallel(cl)
clusterEvalQ(cl, library(dplyr)) #load dplyr in all workers
loading_grid <- expand.grid(f1=seq(0.2, 0.8, .05), f2=seq(0.2, 0.8, 0.05))
mlist_rand <- foreach(i=iter(loading_grid, by='row')) %dopar% {
      mm <- model1
      mm$lambda[1, 2] <- i$f1 #runif(1, 0.2, 0.8) #random loading of y2 onto f1
      mm$lambda[2, 2] <- i$f2  #runif(1, 0.2, 0.8) #random loading of y2 onto f2
      sims <- simCFAGraphs(mm, nreplications=5, n=400, thetastart=TRUE, parallel=0)
      return(sims)
}
stopCluster(cl)
```

```{r dependson="sim_2fac_cross_rand", include=FALSE}
#will return a data.frame with betweenness for y2 (cross-loaded item) and the population
#and fitted loadings for both factors
bmat_rand <- do.call(rbind, lapply(mlist_rand, function(rep) {
  brep <- filter(rep$graph_v_factor$EBICglasso$metric_v_loadings, node=="y2" & measure=="betweenness")
}))

bmat_rand$graphNum <- rep(1:(nrow(bmat_rand)/2), each=2) #bmat has two rows per replication. Need to identify these to get the spread to work properly

smat_rand <- do.call(rbind, lapply(mlist_rand, function(rep) {
  brep <- filter(rep$graph_v_factor$EBICglasso$metric_v_loadings, node=="y2" & measure=="strength")
}))

smat_rand$graphNum <- rep(1:(nrow(smat_rand)/2), each=2) #smat has two rows per replication. Need to identify these to get the spread to work properly

cmat_rand <- do.call(rbind, lapply(mlist_rand, function(rep) {
  brep <- filter(rep$graph_v_factor$EBICglasso$metric_v_loadings, node=="y2" & measure=="closeness")
}))

cmat_rand$graphNum <- rep(1:(nrow(cmat_rand)/2), each=2) #smat has two rows per replication. Need to identify these to get the spread to work properly

#look at how the correlation matrix is affected
corr_rand <- do.call(rbind, lapply(mlist_rand, function(rep) {
  wif1 <- rep$adjmats$pearson$average[c(1,3:9), c(1,3:9)]
  wif1m <- mean(wif1[lower.tri(wif1)])
  wif2 <- rep$adjmats$pearson$average[10:18, 10:18]
  wif2m <- mean(wif2[lower.tri(wif2)])
  bwf1f2m <- mean(rep$adjmats$pearson$average[c(1,3:9), 10:18])
  f1y2m <- mean(rep$adjmats$pearson$average[2, c(1,3:9)]) #correlation of target item (y2) with other items on f1
  f2y2m <- mean(rep$adjmats$pearson$average[2, 10:18]) #correlation of target item (y2) with other items on f2
  
  data.frame(wif1m=wif1m, wif2m=wif2m, bwf1f2m=bwf1f2m, f1y2m=f1y2m, f2y2m=f2y2m,
             f1loading=select(rep[["simsemout"]]@coef, matches("f1=~y2")),
             f2loading=select(rep[["simsemout"]]@coef, matches("f2=~y2")))
}))

```

```{r}
Hmisc::rcorr(as.matrix(corr_rand))

#summary(lm(bwf1f2m ~ f1..y2 * f2..y2, corr_rand))
```


Conclusions about effects of cross-loading on correlations among items:
1. Higher factor loading of y2 on f1 goes with higher average correlation (r = .90) of y2 with y1-y9 (other f1 items): obvious
2. Converse: Higher factor loading of y2 on f2 goes with higher average correlation (r = .91) of y2 with y10-y18 (other f2 items): obvious
3. Higher factor loading of y2 on f2 goes with lower average correlation (r = -.35) on f1. So loading drives similarity to primary factor and dissimilarity to cross-loaded factor. Converse holds, too (y2 on f1)
4. Non-trivial: Higher correlation of y2 with f1 items associated with lower correlation with f2 items, r = -.63.
```{r}
cor.test(~ fittedloading + value, filter(bmat_rand, factor=="f2"))
cor.test(~ fittedloading + value, filter(bmat_rand, factor=="f1"))

cor.test(~ fittedloading + value, filter(cmat_rand, factor=="f2"))
cor.test(~ fittedloading + value, filter(cmat_rand, factor=="f1"))

cor.test(~ fittedloading + value, filter(smat_rand, factor=="f2"))
cor.test(~ fittedloading + value, filter(smat_rand, factor=="f1"))

#bb_rand <- smat_rand %>% select(graphNum, value, factor, fittedloading) %>% spread(key=factor, value=fittedloading)
bb_rand <- smat_rand %>% select(graphNum, value, factor, poploading) %>% spread(key=factor, value=poploading) #graphNum contains the identifying column
ggplot(bb_rand, aes(x=f1, y=value)) + geom_point() + stat_smooth()
summary(lm(value ~ f1 + f2, bb_rand)) #so measure becomes hugely predicted by each loading

#3d plot of sorts
ggplot(bb_rand, aes(x=f1, y=f2, color=value)) + geom_jitter(size=3) + scale_color_gradient()
```


### Residual correlation
Simulate residual correlations on 2-D grid of cross-loadings for four items: y1, y2 (f1); y10, y11 (f2)
Residual correlations range in strength from 0.0 - 0.8 in .05 increments
```{r sim_2fac_residcorr, cache=TRUE, include=FALSE}
cl <- makeCluster(8) #defaults to PSOCK cluster
clusterExport(cl, c("simCFAGraphs"))

registerDoParallel(cl)
clusterEvalQ(cl, library(dplyr)) #load dplyr in all workers
loading_grid <- expand.grid(cl1=seq(0.0, 0.8, .05), cl2=seq(0.0, 0.8, 0.05))
mlist_crossload <- foreach(i=iter(loading_grid, by='row')) %dopar% {
      mm <- model1
      mm$theta <- addErrorCor(mm$theta, c("y1", "y10"), i$cl1)
      mm$theta <- addErrorCor(mm$theta, c("y2", "y11"), i$cl2)
      sims <- simCFAGraphs(mm, nreplications=5, n=400, thetastart=TRUE, parallel=0)
      return(sims)
}
stopCluster(cl)
```

```{r dependson="sim_2fac_residcorr"}
#@smat_rand <- do.call(rbind, 
smat_rand <- do.call(bind_rows, lapply(mlist_crossload, function(rep) {
  #filter to only those items that allowed resid corr
  srep <- filter(rep$graph_v_factor$EBICglasso$metric_v_loadings, node %in% c("y1", "y2", "y10", "y11") & measure=="closeness")
})) #bind_rows from dplyr automatically fills NAs (this is needed here since 0, 0 is one cell in the crossloading)

summary(lm(value ~ fittedloading, filter(smat_rand, node=="y1")))
summary(lm(value ~ rcorr_pop, filter(smat_rand, node=="y1")))
summary(lm(value ~ rcorr_fitted, filter(smat_rand, node=="y1")))
summary(lm(value ~ rcorr_fitted + I(rcorr_fitted^2), filter(smat_rand, node=="y1")))
summary(lm(value ~ rcorr_fitted * fittedloading, filter(smat_rand, node=="y1")))
#correlations are added to theta by r * sqrt(V1)*sqrt(V2) to respect the residual variances of the indicators
#to scale back onto correlation, we undo this by standardization: b / [sqrt(V1) * sqrt(V2)]
#here we have indicators of 0.3 in both cases, so just divide by 0.3. Technically should use fitted vars
#to get this exactly right, but this is a trivial difference
range(smat_rand$rcorr_pop/0.3, na.rm=T)
ggplot(smat_rand, aes(x=rcorr_fitted/0.3, y=value, color=fittedloading)) + facet_wrap(~node) + geom_point()

smat_rand$graphNum <- rep(1:(nrow(smat_rand)/2), each=2) #smat has two rows per replication. Need to identify these to get the spread to work properly


bb_rand <- smat_rand %>% select(graphNum, value, factor, poploading) %>% spread(key=factor, value=poploading) #graphNum contains the identifying column
ggplot(bb_rand, aes(x=f1, y=value)) + geom_point() + stat_smooth()
summary(lm(value ~ f1 + f2, bb_rand)) #so measure becomes hugely predicted by each loading


###

#should probably reshape to allow for MLM where nodes are random
#initial corroboration for hypothesis 2
# mm <- do.call(rbind, mlist)
# my1 <- filter(mm, node=="y1")
# summary(lm(value ~ y10, my1)) #betweenness of y1 predicted by residual correlation with y10
# cor.test(~ value + y10, my1) #r ~ 0.55
# 
# my10 <- filter(mm, node=="y10")
# summary(lm(value ~ y1, my10)) #betweenness of y10 predicted by residual correlation with y1
# cor.test(~ value + y1, my10)
```